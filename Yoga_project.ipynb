{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlDLIKbREO1_"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zTj610zEfu6"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"info.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asana_dataset = pd.read_csv('Book1.csv')"
      ],
      "metadata": {
        "id": "L29lu4wQeGDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyprNI5rHSDW"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asana_dataset['asanas']"
      ],
      "metadata": {
        "id": "sOYUttr4ee0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQCPw3x1VHkb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "corpus = []\n",
        "for i in range(0, 38):\n",
        "  processed_data = re.sub('[^a-zA-Z]', ' ', data['Benefits'][i])\n",
        "  processed_data = processed_data.lower()\n",
        "  processed_data = processed_data.split()\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  processed_data = [word for word in processed_data if not word in set(all_stopwords)]\n",
        "  processed_data = ' '.join(processed_data)\n",
        "  corpus.append(processed_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,38):\n",
        "  data['Benefits'][i] = corpus[i]"
      ],
      "metadata": {
        "id": "wMllkTISrTkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "mxQAZtH6rwOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = data.Benefits.apply(gensim.utils.simple_preprocess) #Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long."
      ],
      "metadata": {
        "id": "NZsNFfsztojh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final"
      ],
      "metadata": {
        "id": "xyryVlg-vWzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final)"
      ],
      "metadata": {
        "id": "dawqTp7Der-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connected_dataset = [] #list of asanas Asanas according to the respective number of cleaned words."
      ],
      "metadata": {
        "id": "hbiKizgcewDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(final)):\n",
        "  for j in range(len(final[i])):\n",
        "    connected_dataset.append(asana_dataset['asanas'][i])"
      ],
      "metadata": {
        "id": "L4THJ-0KepiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(connected_dataset)"
      ],
      "metadata": {
        "id": "AA4HDYOXgH3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connected_dataset"
      ],
      "metadata": {
        "id": "FPCvkWWj7bf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYtSYwGcqdyN"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences = final, sg=1, min_count=1, workers=4, window = 5, size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf6xTAM2qd1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9f22f8-9c31-4279-95fd-d004253cb3f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(529470, 826000)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "model.train(final, total_examples=model.corpus_count, epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['peacock']"
      ],
      "metadata": {
        "id": "QKgnxMEoA-hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.wv.vocab)"
      ],
      "metadata": {
        "id": "K5navScWuLJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final"
      ],
      "metadata": {
        "id": "02AJ0oAhntSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7wZKfe5q5pJ"
      },
      "outputs": [],
      "source": [
        "model.wv.word_vec('pain') #another way to get embeddings of a word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final[0][0]"
      ],
      "metadata": {
        "id": "NIKQR-SIo9H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"depression\", topn = 10 )"
      ],
      "metadata": {
        "id": "RsMpwcKupG_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dash = []\n",
        "for i in range(len(final)):\n",
        "  for j in final[i]:\n",
        "    embeddings_dash.append(model.wv[j])"
      ],
      "metadata": {
        "id": "DODcVmzjoEnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings_dash)"
      ],
      "metadata": {
        "id": "nJyBz7PGoGuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj_7sJJnrG27"
      },
      "outputs": [],
      "source": [
        "embeddings_dash[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Pw-3h_ixMQ_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(embeddings_dash)):\n",
        "#   embeddings_dash[i] = np.pad(embeddings_dash[i],(6,6)) #when we one hot encoded the asanas, its number is elements were 32. therefore we pad 6 zeros in front and 6 at the back."
      ],
      "metadata": {
        "id": "h51kZkvTuxwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings_dash[0])"
      ],
      "metadata": {
        "id": "S-Bh3x06vAme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dash[0]"
      ],
      "metadata": {
        "id": "AIIsAkiBq6OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final[0][0]"
      ],
      "metadata": {
        "id": "MqO1AmUzr9pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embeddings_dash = np.array(embeddings_dash)"
      ],
      "metadata": {
        "id": "0QQ1KlduiO7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dash"
      ],
      "metadata": {
        "id": "5EHbcoxAihGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(array):\n",
        "    unique, inverse = np.unique(array, return_inverse=True)\n",
        "    onehot = np.eye(unique.shape[0])[inverse]\n",
        "    return onehot"
      ],
      "metadata": {
        "id": "am8R_0L4jEUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = one_hot(connected_dataset)"
      ],
      "metadata": {
        "id": "uKGv4g90jFto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = arr"
      ],
      "metadata": {
        "id": "mHAt7p0Zl8sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "cMpXxKvN8iuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(output)"
      ],
      "metadata": {
        "id": "AX8V3edgjmaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = embeddings_dash"
      ],
      "metadata": {
        "id": "NjsNCHuz78yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input)"
      ],
      "metadata": {
        "id": "yFdaRH0725Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input.shape"
      ],
      "metadata": {
        "id": "h8sdSzsZ5iFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape = input.shape"
      ],
      "metadata": {
        "id": "QHmjRY4c2XVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "iVlmu5FO2_0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "AO8ZXZj6jy0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "MVhWqph3jZhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(220, activation='relu'))"
      ],
      "metadata": {
        "id": "IYJjPbNWjFqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=32, activation='softmax'))"
      ],
      "metadata": {
        "id": "D6GdiT_c9MhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QSV07urnjFnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(input, output, batch_size = 5, epochs = 100)"
      ],
      "metadata": {
        "id": "ERiS2-88jFkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = []\n",
        "test.append(model.wv['pain'])\n",
        "test.append(model.wv['peacock'])\n",
        "test = np.array(test)\n",
        "test"
      ],
      "metadata": {
        "id": "RUP-0aSRjFhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(asana_dataset['asanas'])):\n",
        "  for j in ann.predict(test):\n",
        "    if i == np.argmax(j):\n",
        "      print(asana_dataset['asanas'][i])"
      ],
      "metadata": {
        "id": "aoqpJxU7jFee"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Yoga project summer 2022.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}